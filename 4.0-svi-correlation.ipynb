{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal: To see if an areas Social Vulnerability Index score correlates to an area's amount of crime\n",
    "\n",
    "#### Intended Result: to walk away with some understanding of if certian types of crime correlate to an areas level of vulnerability\n",
    "\n",
    "###### Background: Social Vulnerability Index (SVI)\n",
    "\n",
    "The Socially Vulnerable Population Analysis uses measurements of a geographical area's relative level of vulnerability across multiple variables measure by the American Community Survey. These measurements are derived from The Center for Disease Control's 2016 Social Vulnerability Index (SVI)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets read in the data from some csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('clean_crime_data.csv',dtype = {'zip_code':object})\n",
    "svi = pd.read_csv('census-data/svi_data.csv', dtype = {'zip':object})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right now the data is structured very similar to how an excel file is structured. We are going to turn the two dataframes into spark dataframes, which is something that is really useful for working with large data sets (due to computational reasons). This is kind of overkill for these datasets, but its cool and will also allow us to query these data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = pyspark.sql.SparkSession.builder.appName('pandasToSparkDF').getOrCreate()\n",
    "\n",
    "# create spark dataframes\n",
    "crime_df = spark.createDataFrame(df)\n",
    "svi_df = spark.createDataFrame(svi)\n",
    "\n",
    "# write them to a database\n",
    "for name, data in zip(['crime','svi'],[crime_df,svi_df]):\n",
    "    data.createOrReplaceTempView(str(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+------------------+--------+---------+------+-----------------+---+--------+----------+---------------+-------------+-----------------+---------------+---------------+----------------+-----------------+---------+---------+---------+---------+---------+---------+---------+-----------+---------+--------+----------+-----+-------+---------+----------+---------+---------+------------------+----------+----------+----------+---------+----------+---------+---------+----------+----------+----------+----------+----------+----------+----------+----------+----------+\n",
      "|     crime_id|from_date|       description|zip_code|charge_id|dvflag|firearm_used_flag|arr|male_arr|female_arr|black_race_flag|nan_race_flag|unknown_race_flag|white_race_flag|asian_race_flag|indian_race_flag|pacific_race_flag|age_minor|age_18_24|age_25_29|age_30_34|age_35_39|age_40_44|age_45_49|age_50_plus|total_vic|male_vic|male_vic.1|  zip|epl_pov|epl_unemp|epl_nohsdp|epl_age65|epl_age17|        epl_disabl|epl_sngpnt|epl_minrty|epl_limeng|epl_munit|epl_mobile|epl_crowd|epl_noveh|epl_groupq|spl_theme1|spl_theme2|spl_theme3|rpl_theme1|rpl_theme2|rpl_theme3|rpl_theme4|rpl_themes|\n",
      "+-------------+---------+------------------+--------+---------+------+-----------------+---+--------+----------+---------------+-------------+-----------------+---------------+---------------+----------------+-----------------+---------+---------+---------+---------+---------+---------+---------+-----------+---------+--------+----------+-----+-------+---------+----------+---------+---------+------------------+----------+----------+----------+---------+----------+---------+---------+----------+----------+----------+----------+----------+----------+----------+----------+----------+\n",
      "|160050412_621|7/13/2016|Stealing All Other|   64030|      621|     0|                0|  1|       0|         1|              1|            0|                0|              0|              0|               0|                0|        0|        0|        0|        1|        0|        0|        0|          0|      0.0|     0.0|       0.0|64030| 0.7289|   0.6558|    0.5502|   0.1447|   0.8924|0.6729999999999999|    0.9334|    0.8654|    0.7829|   0.8631|    0.1811|   0.7568|   0.6541|    0.5327|    1.9349|    2.6435|    1.6483|    0.6864|    0.8774|    0.8634|    0.7235|    0.8607|\n",
      "+-------------+---------+------------------+--------+---------+------+-----------------+---+--------+----------+---------------+-------------+-----------------+---------------+---------------+----------------+-----------------+---------+---------+---------+---------+---------+---------+---------+-----------+---------+--------+----------+-----+-------+---------+----------+---------+---------+------------------+----------+----------+----------+---------+----------+---------+---------+----------+----------+----------+----------+----------+----------+----------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "select * \n",
    "from crime \n",
    "join svi\n",
    "on zip = zip_code\n",
    "\n",
    "\"\"\").limit(1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
