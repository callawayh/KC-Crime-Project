{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal: To see if an areas Social Vulnerability Index score correlates to an area's amount of crime\n",
    "\n",
    "#### Intended Result: to walk away with some understanding of if certian types of crime correlate to an areas level of vulnerability\n",
    "\n",
    "###### Background: Social Vulnerability Index (SVI)\n",
    "\n",
    "The Socially Vulnerable Population Analysis uses measurements of a geographical area's relative level of vulnerability across multiple variables measure by the American Community Survey. These measurements are derived from The Center for Disease Control's 2016 Social Vulnerability Index (SVI)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets read in the data from some csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('clean_crime_data.csv',dtype = {'zip_code':object})\n",
    "svi = pd.read_csv('census-data/svi_data.csv', dtype = {'zip':object})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right now the data is structured very similar to how an excel file is structured. We are going to turn the two dataframes into spark dataframes, which is something that is really useful for working with large data sets (due to computational reasons). This is kind of overkill for these datasets, but its cool and will also allow us to query these data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = pyspark.sql.SparkSession.builder.appName('pandasToSparkDF').getOrCreate()\n",
    "\n",
    "# create spark dataframes\n",
    "crime_df = spark.createDataFrame(df)\n",
    "svi_df = spark.createDataFrame(svi)\n",
    "\n",
    "# write them to a database\n",
    "for name, data in zip(['crime','svi'],[crime_df,svi_df]):\n",
    "    data.createOrReplaceTempView(str(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_crime = spark.sql(\"\"\"\n",
    "select * from \n",
    "    (select \n",
    "    zip_code,\n",
    "    count(distinct crime_id) as total_crimes,\n",
    "    sum(dvflag) as total_dv_flags,  \n",
    "    sum(firearm_used_flag) as total_firearm_flags, \n",
    "    sum(male_arr) as total_male_arr, \n",
    "    sum(female_arr) as total_female_arr,\n",
    "    sum(black_race_flag) as black_race_flag_arr, \n",
    "    sum(unknown_race_flag) as unkown_race_flag_arr,\n",
    "    sum(white_race_flag) as white_race_flag_arr, \n",
    "    sum(asian_race_flag) as asian_race_flag_arr, \n",
    "    sum(indian_race_flag) as indian_race_flag_arr,\n",
    "    sum(pacific_race_flag) as pacific_race_flag_arr, \n",
    "    sum(age_minor) as minor_arr, \n",
    "    sum(age_18_24) as age_18_24_arr, \n",
    "    sum(age_25_29) as age_25_29_arr, \n",
    "    sum(age_30_34) as age_30_34_arr,\n",
    "    sum(age_35_39) as age_35_39_arr, \n",
    "    sum(age_40_44) as age_40_44_arr, \n",
    "    sum(age_45_49) as age_45_49_arr, \n",
    "    sum(age_50_plus) as age_50_plus_arr, \n",
    "    sum(total_vic) as total_victims,\n",
    "    sum(male_vic) as total_male_victims, \n",
    "    sum(female_vic) as total_female_victims\n",
    "from crime\n",
    "group by 1)a\n",
    "join svi s\n",
    "    on s.zip = a.zip_code\n",
    "\n",
    "\"\"\").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see how the aggregate SVI scores of the areas in KC we are looking at are distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = pd.DataFrame(agg_crime[['rpl_themes','rpl_theme1','rpl_theme2','rpl_theme3','rpl_theme4']].describe())\n",
    "dist.rename(columns = {'rpl_themes':'overall_score',\n",
    "                      'rpl_theme1':'overall_socio_econ_score',\n",
    "                      'rpl_theme2':'overall_household_comp_score',\n",
    "                      'rpl_theme3':'overall_minrty_lang_score',\n",
    "                      'rpl_theme4':'overall_housing_trans_score'},inplace = True)\n",
    "d = dist.iloc[[1,3,4,5,6,7]]\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.grid(color='gray', linestyle='-', linewidth=2, alpha = .1)\n",
    "bplot = sns.boxplot(data=d,\n",
    "                    width=0.5,\n",
    "                    palette=\"deep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like KC is pretty average as far as our SVI Scores for various zipcodes. We do have a fairly good distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going to use a spearman correlation because one varible we are measuring, crime (and its various attributes) is continous while the SVI data is ordinal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = agg_crime.corr(method='spearman',)\n",
    "\n",
    "c = corr.loc['total_crimes':'total_female_victims','epl_pov':'epl_groupq']\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.xticks(np.arange(len(c)), rotation=45, ha='right')\n",
    "sns.set_style(style = 'white')\n",
    "cmap = sns.diverging_palette(250, 10, as_cmap=True)\n",
    "sns.heatmap(c, \n",
    "            xticklabels=c.columns.values,\n",
    "            yticklabels=c.index.values,\n",
    "            annot = True,\n",
    "           cmap = cmap)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
