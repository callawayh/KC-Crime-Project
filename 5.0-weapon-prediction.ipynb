{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal: to build a model that predicts if a weapon was used or not based on the attributes of that crime\n",
    "\n",
    "This will use a binary outcome of true or false. I will try using bayesian model, logistic regression, random forrest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyspark\n",
    "import numpy\n",
    "from pyspark.sql import functions as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('clean_crime_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am not sure how many crime involved the use of a weapon. Lets look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "401"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df.firearm_used_flag >=1]) # this feels like a cumbersome approach. Lets do something cool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crimes where weapon was used\n",
      "+-----------+--------------------+\n",
      "|crime_count|         description|\n",
      "+-----------+--------------------+\n",
      "|         93|  Aggravated Assault|\n",
      "|         55|Aggravated Assaul...|\n",
      "|          8|Non Aggravated As...|\n",
      "|          6|       Armed Robbery|\n",
      "|          5|Non Aggravated As...|\n",
      "|          2|  Strong Arm Robbery|\n",
      "|          1|                Rape|\n",
      "|          1|Kidnapping/Abduction|\n",
      "|          1|            Homocide|\n",
      "+-----------+--------------------+\n",
      "\n",
      "all crimes\n",
      "+-----------+\n",
      "|crime_count|\n",
      "+-----------+\n",
      "|      30400|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark = pyspark.sql.SparkSession.builder.appName('pandasToSparkDF').getOrCreate()\n",
    "\n",
    "# create spark dataframes\n",
    "crime_df = spark.createDataFrame(df)\n",
    "\n",
    "crime_df.createOrReplaceTempView('crime')\n",
    "\n",
    "print('crimes where weapon was used')\n",
    "\n",
    "gun_crimes = spark.sql(\"\"\"\n",
    "select \n",
    "    count(distinct crime_id) as crime_count,\n",
    "    description\n",
    "from crime\n",
    "where firearm_used_flag >= 1\n",
    "and description not LIKE '%Weapons%'\n",
    "group by 2 order by 1 desc\n",
    "\"\"\")\n",
    "\n",
    "gun_crimes.show()\n",
    "\n",
    "print('all crimes')\n",
    "\n",
    "all_crimes = spark.sql(\"\"\"\n",
    "select\n",
    "count(distinct crime_id) as crime_count\n",
    "from crime\n",
    "\"\"\")\n",
    "\n",
    "all_crimes.show()\n",
    "\n",
    "#print('Weapons were used in {}% of the crimes in this data set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weapons were used in 0.6% of the crimes in this data set\n"
     ]
    }
   ],
   "source": [
    "print('Weapons were used in {}% of the crimes in this data set'.format(round((gun_crimes.groupBy().sum().collect()[0][0]/\n",
    "                                                                            all_crimes.groupBy().sum().collect()[0][0]),3)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok. This might seem pretty bad but actually there are a ton of types of crimes that we can exclude to narrow our focus and give this percentage a bit more of a fighting chance! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc = gun_crimes.toPandas()\n",
    "gc.drop([6], axis= 0, inplace = True)\n",
    "\n",
    "data = df[df.description.isin(gc.description.unique())]\n",
    "data.reset_index(inplace = True,drop = True)\n",
    "data = data.drop_duplicates(subset=['crime_id'], keep = False) \n",
    "data.firearm_used_flag = np.where(data.firearm_used_flag >= 1,1,0)\n",
    "data.dvflag = np.where(data.dvflag >= 1,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now we have 2.37% of the crimes in this data set involving a firearm\n"
     ]
    }
   ],
   "source": [
    "print('now we have {}% of the crimes in this data set involving a firearm'.format(round((len(data[data.firearm_used_flag>=1])/\n",
    "                                                                                 len(data[data.firearm_used_flag<1]))*100,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this will be much better! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naieve Bayes Classifer \n",
    "\n",
    "I will be using the Complement Naive Bayes (CNB) algorithm. CNB is an adaptation of the standard multinomial naive Bayes (MNB) algorithm that is particularly suited for imbalanced data sets. Given that we are trying to predict an event that only occurs ~2% of the time, this is a good choice.\n",
    "\n",
    "https://www.youtube.com/watch?v=CPqOCI0ahss\n",
    "\n",
    "This is a really good video of explaining how a Naieve Bayes model works at a high level. Its really pretty simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_no_gun</th>\n",
       "      <th>pred_gun</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual_no_gun</th>\n",
       "      <td>715</td>\n",
       "      <td>368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual_gun</th>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               pred_no_gun  pred_gun\n",
       "actual_no_gun          715       368\n",
       "actual_gun              12        13"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import ComplementNB\n",
    "\n",
    "# split the data, will use this same data for other models \n",
    "model_df = data.loc[:,'dvflag':]\n",
    "model_df_data = model_df.drop(columns=['firearm_used_flag'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(model_df_data,model_df['firearm_used_flag'],test_size = .15,\n",
    "                                                    random_state = 42)\n",
    "# train the model\n",
    "model = ComplementNB().fit(X_train, y_train)\n",
    "predicted = model.predict(X_test)\n",
    "\n",
    "# put results to a confusion matrix\n",
    "nb_results = pd.DataFrame(confusion_matrix(y_test, predicted), columns=['pred_no_gun','pred_gun'],\n",
    "             index = ['actual_no_gun','actual_gun'])\n",
    "nb_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Ok, this model is better than flipping a coin, but it is not that good. Lets break it down some:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelStats(results):\n",
    "    accuracy = ((results.loc['actual_no_gun','pred_no_gun'] +results.loc['actual_gun','pred_gun'])/results.values.sum())*100\n",
    "    mis_class = ((results.loc['actual_gun','pred_no_gun'] +results.loc['actual_no_gun','pred_gun'])/results.values.sum())*100\n",
    "    true_pos = ((results.loc['actual_gun','pred_gun']/results.loc['actual_gun'].sum()))*100\n",
    "    false_pos = ((results.loc['actual_no_gun','pred_gun']/results.loc['actual_no_gun'].sum()))*100\n",
    "    true_neg = ((results.loc['actual_no_gun','pred_no_gun']/results.pred_no_gun.sum()))*100\n",
    "    precision = ((results.loc['actual_gun','pred_gun']/results.pred_gun.sum()))*100\n",
    "    prevalence = (results.loc['actual_gun'].sum()/results.values.sum())*100\n",
    "\n",
    "    print('The model was {}% accuracte'.format(round(accuracy,2)))\n",
    "    print('The model had a misclassification rate of {}%'.format(round(mis_class,2)))\n",
    "    print('The model had a true positive rate of {}%'.format(round(true_pos,2)))\n",
    "    print('The model had a false positive rate of {}%'.format(round(false_pos,2)))\n",
    "    print('The model had a true negitive rate of {}%'.format(round(true_neg,2)))\n",
    "    print('The model had a precision rate of {}%'.format(round(precision,2)))\n",
    "    print('The model had a prevalence rate of {}%'.format(round(prevalence,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model was 65.7% accuracte\n",
      "The model had a misclassification rate of 34.3%\n",
      "The model had a true positive rate of 52.0%\n",
      "The model had a false positive rate of 33.98%\n",
      "The model had a true negitive rate of 98.35%\n",
      "The model had a precision rate of 3.41%\n",
      "The model had a prevalence rate of 2.26%\n"
     ]
    }
   ],
   "source": [
    "modelStats(nb_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
