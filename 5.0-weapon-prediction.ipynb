{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal: to build a model that predicts if a weapon was used or not based on the attributes of that crime\n",
    "\n",
    "This will use a binary outcome of true or false. I will try using bayesian model, logistic regression, random forrest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyspark\n",
    "import numpy\n",
    "from pyspark.sql import functions as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('clean_crime_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am not sure how many crime involved the use of a weapon. Lets look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "401"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df.firearm_used_flag >=1]) # this feels like a cumbersome approach. Lets do something cool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crimes where weapon was used\n",
      "+-----------+--------------------+\n",
      "|crime_count|         description|\n",
      "+-----------+--------------------+\n",
      "|         93|  Aggravated Assault|\n",
      "|         55|Aggravated Assaul...|\n",
      "|          8|Non Aggravated As...|\n",
      "|          6|       Armed Robbery|\n",
      "|          5|Non Aggravated As...|\n",
      "|          2|  Strong Arm Robbery|\n",
      "|          1|                Rape|\n",
      "|          1|            Homocide|\n",
      "|          1|Kidnapping/Abduction|\n",
      "+-----------+--------------------+\n",
      "\n",
      "all crimes\n",
      "+-----------+\n",
      "|crime_count|\n",
      "+-----------+\n",
      "|      30400|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark = pyspark.sql.SparkSession.builder.appName('pandasToSparkDF').getOrCreate()\n",
    "\n",
    "# create spark dataframes\n",
    "crime_df = spark.createDataFrame(df)\n",
    "\n",
    "crime_df.createOrReplaceTempView('crime')\n",
    "\n",
    "print('crimes where weapon was used')\n",
    "\n",
    "gun_crimes = spark.sql(\"\"\"\n",
    "select \n",
    "    count(distinct crime_id) as crime_count,\n",
    "    description\n",
    "from crime\n",
    "where firearm_used_flag >= 1\n",
    "and description not LIKE '%Weapons%'\n",
    "group by 2 order by 1 desc\n",
    "\"\"\")\n",
    "\n",
    "gun_crimes.show()\n",
    "\n",
    "print('all crimes')\n",
    "\n",
    "all_crimes = spark.sql(\"\"\"\n",
    "select\n",
    "count(distinct crime_id) as crime_count\n",
    "from crime\n",
    "\"\"\")\n",
    "\n",
    "all_crimes.show()\n",
    "\n",
    "#print('Weapons were used in {}% of the crimes in this data set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weapons were used in 0.6% of the crimes in this data set\n"
     ]
    }
   ],
   "source": [
    "print('Weapons were used in {}% of the crimes in this data set'.format(round((gun_crimes.groupBy().sum().collect()[0][0]/\n",
    "                                                                            all_crimes.groupBy().sum().collect()[0][0]),3)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok. This might seem pretty bad but actually there are a ton of types of crimes that we can exclude to narrow our focus and give this percentage a bit more of a fighting chance! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc = gun_crimes.toPandas()\n",
    "gc.drop([6], axis= 0, inplace = True)\n",
    "\n",
    "data = df[df.description.isin(gc.description.unique())]\n",
    "data.reset_index(inplace = True,drop = True)\n",
    "data = data.drop_duplicates(subset=['crime_id'], keep = False) \n",
    "data.firearm_used_flag = np.where(data.firearm_used_flag >= 1,1,0)\n",
    "data.dvflag = np.where(data.dvflag >= 1,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now we have 2.37% of the crimes in this data set involving a firearm\n"
     ]
    }
   ],
   "source": [
    "print('now we have {}% of the crimes in this data set involving a firearm'.format(round((len(data[data.firearm_used_flag>=1])/\n",
    "                                                                                 len(data[data.firearm_used_flag<1]))*100,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this will be much better! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naieve Bayes Classifer \n",
    "\n",
    "I will be using the Complement Naive Bayes (CNB) algorithm. CNB is an adaptation of the standard multinomial naive Bayes (MNB) algorithm that is particularly suited for imbalanced data sets. Given that we are trying to predict an event that only occurs ~2% of the time, this is a good choice.\n",
    "\n",
    "https://www.youtube.com/watch?v=CPqOCI0ahss\n",
    "\n",
    "This is a really good video of explaining how a Naieve Bayes model works at a high level. Its really pretty simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_no_gun</th>\n",
       "      <th>pred_gun</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual_no_gun</th>\n",
       "      <td>935</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual_gun</th>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               pred_no_gun  pred_gun\n",
       "actual_no_gun          935       148\n",
       "actual_gun               2        23"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import ComplementNB\n",
    "\n",
    "# split the data, will use this same data for other models \n",
    "model_df = data.drop(columns=['crime_id','from_date','charge_id'])\n",
    "\n",
    "description = pd.get_dummies(model_df['description'])\n",
    "zipcode = pd.get_dummies(model_df['zip_code'])\n",
    "\n",
    "model_df_2 = pd.concat([model_df,description,zipcode], axis = 1)\n",
    "\n",
    "model_df_data = model_df_2.drop(columns=['firearm_used_flag','description','zip_code'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(model_df_data,model_df_2['firearm_used_flag'],test_size = .15,\n",
    "                                                    random_state = 42)\n",
    "# train the model\n",
    "model = ComplementNB().fit(X_train, y_train)\n",
    "predicted = model.predict(X_test)\n",
    "\n",
    "# # put results to a confusion matrix\n",
    "nb_results = pd.DataFrame(confusion_matrix(y_test, predicted), columns=['pred_no_gun','pred_gun'],\n",
    "             index = ['actual_no_gun','actual_gun'])\n",
    "nb_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Ok, this model feels alright. Lets break it down some:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelStats(results):\n",
    "    accuracy = ((results.loc['actual_no_gun','pred_no_gun'] +results.loc['actual_gun','pred_gun'])/results.values.sum())*100\n",
    "    mis_class = ((results.loc['actual_gun','pred_no_gun'] +results.loc['actual_no_gun','pred_gun'])/results.values.sum())*100\n",
    "    true_pos = ((results.loc['actual_gun','pred_gun']/results.loc['actual_gun'].sum()))*100\n",
    "    false_pos = ((results.loc['actual_no_gun','pred_gun']/results.loc['actual_no_gun'].sum()))*100\n",
    "    true_neg = ((results.loc['actual_no_gun','pred_no_gun']/results.pred_no_gun.sum()))*100\n",
    "    precision = ((results.loc['actual_gun','pred_gun']/results.pred_gun.sum()))*100\n",
    "    prevalence = (results.loc['actual_gun'].sum()/results.values.sum())*100\n",
    "\n",
    "    print('The model was {}% accuracte'.format(round(accuracy,2)))\n",
    "    print('The model had a misclassification rate of {}%'.format(round(mis_class,2)))\n",
    "    print('The model had a true positive rate of {}%'.format(round(true_pos,2)))\n",
    "    print('The model had a false positive rate of {}%'.format(round(false_pos,2)))\n",
    "    print('The model had a true negitive rate of {}%'.format(round(true_neg,2)))\n",
    "    print('The model had a precision rate of {}%'.format(round(precision,2)))\n",
    "    print('The model had a prevalence rate of {}%'.format(round(prevalence,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model was 86.46% accuracte\n",
      "The model had a misclassification rate of 13.54%\n",
      "The model had a true positive rate of 92.0%\n",
      "The model had a false positive rate of 13.67%\n",
      "The model had a true negitive rate of 99.79%\n",
      "The model had a precision rate of 13.45%\n",
      "The model had a prevalence rate of 2.26%\n"
     ]
    }
   ],
   "source": [
    "modelStats(nb_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression \n",
    "Logistic regression used a logit function, which is basically a line that spans between 0 and 1. This is due to the formula for this line being 1/(1+e)^-z where e is Eulers number (2.71....) and z is a liner regression line (y=mx+b...) for the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_no_gun</th>\n",
       "      <th>pred_gun</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual_no_gun</th>\n",
       "      <td>1083</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual_gun</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               pred_no_gun  pred_gun\n",
       "actual_no_gun         1083         0\n",
       "actual_gun              24         1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logmodel = LogisticRegression(solver= 'liblinear')\n",
    "\n",
    "# using same data from the previous split\n",
    "logmodel.fit(X_train, y_train,)\n",
    "\n",
    "log_pred = logmodel.predict(X_test)\n",
    "\n",
    "log_results = pd.DataFrame(confusion_matrix(y_test, log_pred), columns=['pred_no_gun','pred_gun'],\n",
    "             index = ['actual_no_gun','actual_gun'])\n",
    "log_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model was 97.83% accuracte\n",
      "The model had a misclassification rate of 2.17%\n",
      "The model had a true positive rate of 4.0%\n",
      "The model had a false positive rate of 0.0%\n",
      "The model had a true negitive rate of 97.83%\n",
      "The model had a precision rate of 100.0%\n",
      "The model had a prevalence rate of 2.26%\n"
     ]
    }
   ],
   "source": [
    "modelStats(log_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is pretty bad. In reality, you could get a decent score by just guessing no gun every single time which is kind of what happened here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
